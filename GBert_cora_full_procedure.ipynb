{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d99aaa",
   "metadata": {},
   "source": [
    "# Load Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torch_sparse/_convert_cpu.so, 0x0006): Symbol not found: __ZN2at8internal15invoke_parallelExxxRKNSt3__18functionIFvxxEEE\n",
      "  Referenced from: <10480BD5-33A4-3A5E-8C3D-8961DBA73F4E> /opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torch_sparse/_convert_cpu.so\n",
      "  Expected in:     <616791F0-29C3-3F88-8A88-D072E7E40979> /opt/anaconda3/envs/Python_interpre/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "content_path = './data/Cora/cora.content'\n",
    "cites_path = './data/Cora/cora.cites'\n",
    "\n",
    "content_df = pd.read_csv(content_path, sep='\\t', header=None)\n",
    "\n",
    "paper_ids = content_df[0].tolist()  \n",
    "features = torch.tensor(content_df.iloc[:, 1:-1].values, dtype=torch.float) \n",
    "labels_raw = content_df.iloc[:, -1].tolist()  \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = torch.tensor(label_encoder.fit_transform(labels_raw), dtype=torch.long)\n",
    "\n",
    "id_map = {pid: i for i, pid in enumerate(paper_ids)}\n",
    "\n",
    "cites_df = pd.read_csv(cites_path, sep='\\t', header=None, names=['source', 'target'])\n",
    "\n",
    "cites_df = cites_df[cites_df['source'].isin(id_map) & cites_df['target'].isin(id_map)]\n",
    "\n",
    "src = cites_df['source'].map(id_map).tolist()\n",
    "dst = cites_df['target'].map(id_map).tolist()\n",
    "\n",
    "edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "data_raw = Data(x=features, edge_index=edge_index, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9968651",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw # data = data_preprocess\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "########## one-hot encoding\n",
    "num_classes = len(data.y.unique())  # Cora has 7 classes\n",
    "\n",
    "# F.one_hot for one-hot coding\n",
    "y_one_hot = F.one_hot(data.y, num_classes=num_classes).float()  # cora dataset shape: [2708, 7] or ABIDE dataset shape: [270000, 2]\n",
    "\n",
    "data.num_nodes = data.x.shape[0]\n",
    "data.node_list = list(range(data.num_nodes))  # initial nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77c375",
   "metadata": {},
   "source": [
    "# intimacy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99276cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/jlhdr74n64dfb6pm21lq8x180000gn/T/ipykernel_47623/606168343.py:33: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_e3pikzc5fh/croot/libtorch_1738337599132/work/torch/csrc/utils/tensor_new.cpp:653.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import inv\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "########## one-hot encoding\n",
    "num_classes = len(data.y.unique())  # Cora has 7 classes\n",
    "\n",
    "# F.one_hot for one-hot coding\n",
    "y_one_hot = F.one_hot(data.y, num_classes=num_classes).float()  # cora dataset shape: [2708, 7] or ABIDE dataset shape: [270000, 2]\n",
    "\n",
    "\n",
    "# building the adjacency matrix\n",
    "def adj_normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))  # Sum over rows (degrees of nodes)\n",
    "    r_inv = np.power(rowsum, -0.5).flatten()  # Inverse square root of degrees\n",
    "    r_inv[np.isinf(r_inv)] = 0.  # Handle division by zero (e.g., for isolated nodes)\n",
    "    r_mat_inv = sp.diags(r_inv)  # Create a sparse diagonal matrix from the inverse degrees\n",
    "    mx = r_mat_inv.dot(mx).dot(r_mat_inv)  # Apply the normalization formula\n",
    "    return mx\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "edges_index = data.edge_index.cpu().numpy().T  # [num_edges, 2]\n",
    "adj = sp.coo_matrix(\n",
    "    (np.ones(edges_index.shape[0]), (edges_index[:, 0], edges_index[:, 1])),\n",
    "    shape=(y_one_hot.shape[0], y_one_hot.shape[0]),\n",
    "    dtype=np.float32\n",
    ")\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "norm_adj = adj_normalize(adj + sp.eye(adj.shape[0]))# normalized adjacency matrix\n",
    "\n",
    "data.adj = sparse_mx_to_torch_sparse_tensor(norm_adj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0fbdbd",
   "metadata": {},
   "source": [
    "# Weisfeiler-Lehman (WL) based graph coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac69e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import pickle\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class WLGraphColoring:\n",
    "    def __init__(self, max_iter=2):\n",
    "        self.max_iter = max_iter\n",
    "        self.node_color_dict = {}\n",
    "        self.node_neighbor_dict = {}\n",
    "\n",
    "    def setting_init(self, node_list, edge_index):\n",
    "        for node in node_list:\n",
    "            self.node_color_dict[node] = 1\n",
    "            self.node_neighbor_dict[node] = {}\n",
    "\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            u1, u2 = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "            self.node_neighbor_dict[u1][u2] = 1\n",
    "            self.node_neighbor_dict[u2][u1] = 1\n",
    "\n",
    "    def WL_recursion(self, node_list):\n",
    "        iteration_count = 1\n",
    "        while True:\n",
    "            new_color_dict = {}\n",
    "            for node in node_list:\n",
    "                neighbors = self.node_neighbor_dict[node]\n",
    "                neighbor_color_list = [self.node_color_dict[neb] for neb in neighbors]\n",
    "                color_string_list = [str(self.node_color_dict[node])] + sorted([str(color) for color in neighbor_color_list])\n",
    "                color_string = \"_\".join(color_string_list)\n",
    "                hash_object = hashlib.md5(color_string.encode())\n",
    "                hashing = hash_object.hexdigest()  # Using MD5 hash function\n",
    "                new_color_dict[node] = hashing\n",
    "\n",
    "            color_index_dict = {k: v + 1 for v, k in enumerate(sorted(set(new_color_dict.values())))}\n",
    "            for node in new_color_dict:\n",
    "                new_color_dict[node] = color_index_dict[new_color_dict[node]]\n",
    "\n",
    "            if self.node_color_dict == new_color_dict or iteration_count == self.max_iter:\n",
    "                return  \n",
    "            else:\n",
    "                self.node_color_dict = new_color_dict\n",
    "            iteration_count += 1\n",
    "\n",
    "    def save_coloring(self, save_path):\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(self.node_color_dict, f)\n",
    "\n",
    "    def visualize_graph(self):\n",
    "        G = nx.Graph()\n",
    "        for node, neighbors in self.node_neighbor_dict.items():\n",
    "            for neighbor in neighbors:\n",
    "                G.add_edge(node, neighbor)\n",
    "\n",
    "        node_colors = [self.node_color_dict[node] for node in G.nodes()]\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        nx.draw(G, node_color=node_colors, with_labels=True, cmap=plt.cm.viridis)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Usage example\n",
    "wl_coloring = WLGraphColoring()\n",
    "\n",
    "# Assuming `data.node_list` and `data.edge_index` are your node list and edge index\n",
    "wl_coloring.setting_init(data.node_list, data.edge_index)\n",
    "wl_coloring.WL_recursion(data.node_list)\n",
    "\n",
    "# Save the node color dict\n",
    "saving_path = './results'\n",
    "os.makedirs(os.path.dirname(f\"{saving_path}/WL/WL\"), exist_ok=True)\n",
    "\n",
    "wl_coloring.save_coloring(f'{saving_path}/WL/WL')\n",
    "\n",
    "# Visualize the graph coloring\n",
    "# wl_coloring.visualize_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278a0e5",
   "metadata": {},
   "source": [
    "# Top-k Personalized PageRank neighbor for propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b77e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# PageRank-inspired adjacent matrix for propogation\n",
    "def neumann_approx_inverse(adj, c=0.15, K=10):\n",
    "    \"\"\"\n",
    "    c = 0.15\n",
    "    Neumann series approximation for eigen_adj = 0.15 * inv(I - (1 - 0.15) * A)\n",
    "    A is the normalized adjacency matrix\n",
    "    Returns a sparse matrix\n",
    "    \"\"\"\n",
    "    alpha = 1 - c\n",
    "    A = adj_normalize(adj)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # initial value is ones matrix\n",
    "    result = sp.eye(n, format='csr', dtype=np.float32)\n",
    "    A_power = sp.eye(n, format='csr', dtype=np.float32)  # A^0\n",
    "\n",
    "    for k in range(1, K + 1):\n",
    "        A_power = alpha * A.dot(A_power)  # A^k\n",
    "        result += A_power\n",
    "\n",
    "    return c * result  # c * sum(alpha^k A^k)\n",
    "\n",
    "\n",
    "#Sparse version\n",
    "# def get_top_k_sparse(eigen_adj: sp.spmatrix, k: int):\n",
    "def get_top_k_sparse(adj: sp.spmatrix, c: float, k: int):\n",
    "    \"\"\"\n",
    "    eigen_adj: scipy.sparse.csr_matrix or coo_matrix\n",
    "    k: int\n",
    "    return: dict[node] = [(neighbor, score), ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # PageRank-inspired adjacent matrix for propogation\n",
    "    eigen_adj = neumann_approx_inverse(adj, c=c, K=15)\n",
    "    \n",
    "    dense = eigen_adj.toarray()\n",
    "    n = dense.shape[0]\n",
    "    result_dict = {}\n",
    "    \n",
    "    key_map = None\n",
    "    for i in range(n):\n",
    "        scores = dense[i]\n",
    "        scores[i] = -np.inf # remove self connection\n",
    "        if k < n:\n",
    "            top_k_idx = np.argpartition(-scores, k)[:k]\n",
    "        else:\n",
    "            top_k_idx = np.arange(n)\n",
    "            top_k_idx = top_k_idx[top_k_idx != i]\n",
    "        \n",
    "        # sorting\n",
    "        top_k_idx = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
    "\n",
    "        neighbors = [(idx, scores[idx]) for idx in top_k_idx]\n",
    "        mapped_node = key_map.get(i, i) if key_map else i\n",
    "        mapped_neighbors = [(key_map.get(nid, nid) if key_map else nid, val) for nid, val in neighbors]\n",
    "\n",
    "        result_dict[mapped_node] = mapped_neighbors\n",
    "\n",
    "        \n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "# KBatch = get_top_k_sparse(adj, 0.15, 2)# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9d902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "def BatchHopDistance(node_list, edge_index, k, batch_path):\n",
    "    import pickle\n",
    "    import networkx as nx\n",
    "    \n",
    "    edge_index = edge_index.cpu().numpy()\n",
    "    link_list = list(zip(edge_index[0], edge_index[1]))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(node_list)\n",
    "    G.add_edges_from(link_list)\n",
    "\n",
    "        \n",
    "\n",
    "    with open(f\"{batch_path}/Batch/top_{k}_GraphBatching\", 'rb') as f:\n",
    "        batch_dict = pickle.load(f)\n",
    "\n",
    "    hop_dict = {}\n",
    "\n",
    "    for node in batch_dict:\n",
    "        try:\n",
    "            node_hop_lengths = nx.single_source_shortest_path_length(G, node, cutoff=10)\n",
    "        except:\n",
    "            node_hop_lengths = {}\n",
    "\n",
    "        hop_dict[node] = {}\n",
    "        for neighbor, _ in batch_dict[node]:\n",
    "            hop = node_hop_lengths.get(neighbor, 99)\n",
    "            hop_dict[node][neighbor] = hop\n",
    "\n",
    "    return hop_dict\n",
    "\n",
    "##--------------------------------------------------------\n",
    "# you can define how many neighbors \n",
    "# for k in [1,2,3,4,5,6,7,8]:\n",
    "# for k in [40,50,60,70,80,90,100,110, 120, 130, 140, 150]:\n",
    "for k in [7]:\n",
    "    \n",
    "    # KBatch = get_top_k_sparse(adj, 0.15, k)\n",
    "    KBatch = get_top_k_sparse(adj, 0.15, k)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(f\"{saving_path}/Batch/top_{k}_GraphBatching\"), exist_ok=True)\n",
    "    f = open(f\"{saving_path}/Batch/top_{k}_GraphBatching\", 'wb')\n",
    "    pickle.dump(KBatch, f)\n",
    "    f.close()\n",
    "    \n",
    "    KHop = BatchHopDistance(data.node_list, data.edge_index, k, saving_path)\n",
    "    os.makedirs(os.path.dirname(f\"{saving_path}/Hop/top_{k}_GraphBatchingHop\"), exist_ok=True)\n",
    "    f = open(f\"{saving_path}/Hop/top_{k}_GraphBatchingHop\", 'wb')\n",
    "    pickle.dump(KHop, f)\n",
    "    f.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b82f37",
   "metadata": {},
   "source": [
    "# Create embedding for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ae4c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load WL Dictionary\n",
      "Load Hop Distance Dictionary\n",
      "Load Subgraph Batches\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "def load_hop_wl_batch(save_dir,k):\n",
    "    print('Load WL Dictionary')\n",
    "    f = open(f'{save_dir}/WL/WL', 'rb')\n",
    "    # f = open(f'{save_dir}/WL/cora', 'rb')\n",
    "    wl_dict = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    print('Load Hop Distance Dictionary')\n",
    "    f = open(f'{save_dir}/Hop/top_{k}_GraphBatchingHop', 'rb')\n",
    "    # f = open(f'{save_dir}/Hop/hop_cora_{k}', 'rb')\n",
    "    hop_dict = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    print('Load Subgraph Batches')\n",
    "    f = open(f'{save_dir}/Batch/top_{k}_GraphBatching', 'rb')\n",
    "    # f = open(f'{save_dir}/Batch/cora_{k}', 'rb')\n",
    "    batch_dict = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return hop_dict, wl_dict, batch_dict\n",
    "\n",
    "# Main functions\n",
    "embedding_dimension = 7\n",
    "saving_path = './results'\n",
    "hop_dict, wl_dict, batch_dict = load_hop_wl_batch(saving_path,embedding_dimension)\n",
    "\n",
    "# adj = sparse_mx_to_torch_sparse_tensor(norm_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf20039",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feature_list = []\n",
    "role_ids_list = []\n",
    "position_ids_list = []\n",
    "hop_ids_list = []\n",
    "idx = data.node_list\n",
    "\n",
    "for node in idx:\n",
    "    node_index = node \n",
    "    neighbors_list = batch_dict[node]\n",
    "\n",
    "    raw_feature = [data.x[node_index].tolist()]\n",
    "    role_ids = [wl_dict[node]]\n",
    "    position_ids = range(len(neighbors_list) + 1)\n",
    "    hop_ids = [0]\n",
    "    for neighbor, intimacy_score in neighbors_list:\n",
    "        neighbor_index = neighbor\n",
    "        \n",
    "        raw_feature.append(data.x[neighbor_index].tolist())\n",
    "        role_ids.append(wl_dict[neighbor])\n",
    "        if neighbor in hop_dict[node]:\n",
    "            hop_ids.append(hop_dict[node][neighbor])\n",
    "        else:\n",
    "            hop_ids.append(99)\n",
    "    raw_feature_list.append(raw_feature)\n",
    "    role_ids_list.append(role_ids)\n",
    "    position_ids_list.append(position_ids)\n",
    "    hop_ids_list.append(hop_ids)\n",
    "\n",
    "raw_embeddings = torch.FloatTensor(raw_feature_list)\n",
    "wl_embedding = torch.LongTensor(role_ids_list)\n",
    "hop_embeddings = torch.LongTensor(hop_ids_list)\n",
    "int_embeddings = torch.LongTensor(position_ids_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedb211",
   "metadata": {},
   "source": [
    "# Bert embedding and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82a2ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <367D4265-B20F-34BD-94EB-4F3EE47C385B> /opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/Python_interpre/lib/python3.12/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/Python_interpre/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Concrete MethodModule class for a specific learning MethodModule\n",
    "'''\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.models.bert.modeling_bert import BertPredictionHeadTransform, BertAttention, BertIntermediate, BertOutput\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "\n",
    "BertLayerNorm = torch.nn.LayerNorm\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        self.output_attentions = config.output_attentions\n",
    "        self.output_hidden_states = config.output_hidden_states\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None, head_mask=None, encoder_hidden_states=None, encoder_attention_mask=None, residual_h=None):\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if self.output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask)\n",
    "            hidden_states = layer_outputs[0]\n",
    "\n",
    "            #---- add residual ----\n",
    "            if residual_h is not None:\n",
    "                for index in range(hidden_states.size()[1]):\n",
    "                    hidden_states[:,index,:] += residual_h\n",
    "\n",
    "            if self.output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[1],)\n",
    "\n",
    "        # Add last layer\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if self.output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if self.output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "        return outputs  # last-layer hidden state, (all hidden states), (all attentions)\n",
    "\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from features, wl, position and hop vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        self.raw_feature_embeddings = nn.Linear(config.x_size, config.hidden_size)\n",
    "        self.wl_role_embeddings = nn.Embedding(config.max_wl_role_index, config.hidden_size)\n",
    "        self.inti_pos_embeddings = nn.Embedding(config.max_inti_pos_index, config.hidden_size)\n",
    "        self.hop_dis_embeddings = nn.Embedding(config.max_hop_dis_index, config.hidden_size)\n",
    "        # self.attr_dis_embeddings = nn.Linear(1, config.hidden_size)\n",
    "\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, raw_features=None, wl_role_ids=None, init_pos_ids=None, hop_dis_ids=None, attr_ids=None):\n",
    "\n",
    "        raw_feature_embeds = self.raw_feature_embeddings(raw_features)\n",
    "        # raw_feature_embeds_drop = self.dropout(raw_feature_embeds)\n",
    "        \n",
    "        role_embeddings = self.wl_role_embeddings(wl_role_ids)\n",
    "        # role_embeddings_drop = self.dropout(role_embeddings)\n",
    "        \n",
    "        position_embeddings = self.inti_pos_embeddings(init_pos_ids)\n",
    "        # position_embeddings_drop = self.dropout(position_embeddings)\n",
    "        \n",
    "        hop_embeddings = self.hop_dis_embeddings(hop_dis_ids)\n",
    "        # hop_embeddings_drop = self.dropout(hop_embeddings)\n",
    "        \n",
    "        # attr_embeddings = self.attr_dis_embeddings(attr_ids.unsqueeze(-1))\n",
    "        # attr_embeddings_drop = self.dropout(attr_embeddings)\n",
    "\n",
    "        #---- here, we use summation ----\n",
    "        # embeddings = raw_feature_embeds + role_embeddings + position_embeddings + hop_embeddings + attr_embeddings\n",
    "        embeddings = raw_feature_embeds + role_embeddings + position_embeddings + hop_embeddings\n",
    "        # embeddings = raw_feature_embeds_drop + role_embeddings_drop + position_embeddings_drop + hop_embeddings_drop + attr_embeddings_drop\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "class NodeConstructOutputLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NodeConstructOutputLayer, self).__init__()\n",
    "        self.transform = BertPredictionHeadTransform(config)\n",
    "\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        self.decoder = nn.Linear(config.hidden_size, config.x_size, bias=False)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros(config.x_size))\n",
    "\n",
    "        # Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`\n",
    "        self.decoder.bias = self.bias\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "        hidden_states = self.decoder(hidden_states) + self.bias\n",
    "        return hidden_states\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.is_decoder = config.is_decoder\n",
    "        if self.is_decoder:\n",
    "            self.crossattention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        head_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "    ):\n",
    "        self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "\n",
    "        if self.is_decoder and encoder_hidden_states is not None:\n",
    "            cross_attention_outputs = self.crossattention(\n",
    "                attention_output, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask\n",
    "            )\n",
    "            attention_output = cross_attention_outputs[0]\n",
    "            outputs = outputs + cross_attention_outputs[1:]  # add cross attentions if we output attention weights\n",
    "\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        outputs = (layer_output,) + outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af62057",
   "metadata": {},
   "source": [
    "# Graph Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1003be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Concrete MethodModule class for a specific learning MethodModule\n",
    "'''\n",
    "\n",
    "import torch\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertPooler\n",
    "\n",
    "BertLayerNorm = torch.nn.LayerNorm\n",
    "\n",
    "class MethodGraphBert(BertPreTrainedModel):\n",
    "    data = None\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(MethodGraphBert, self).__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, raw_features, wl_role_ids, init_pos_ids, hop_dis_ids, head_mask=None, residual_h=None):\n",
    "        if head_mask is None:\n",
    "            head_mask = [None] * self.config.num_hidden_layers\n",
    "\n",
    "        embedding_output = self.embeddings(raw_features=raw_features, wl_role_ids=wl_role_ids, init_pos_ids=init_pos_ids, \n",
    "                                        hop_dis_ids=hop_dis_ids)\n",
    "        encoder_outputs = self.encoder(embedding_output, head_mask=head_mask, residual_h=residual_h)\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "        outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n",
    "        \n",
    "        # return outputs, embedding_output, encoder_outputs, sequence_output, pooled_output # Test Output \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98c0c1",
   "metadata": {},
   "source": [
    "# GraphBert Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401371c",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2227cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cora config\n",
    "nclass = len(data.y.unique()) # for cora dataset\n",
    "nfeature = data.x.shape[1]\n",
    "ngraph = data.x.shape[0]\n",
    "\n",
    "#\n",
    "x_size = nfeature\n",
    "y_size = nclass\n",
    "graph_size = ngraph\n",
    "residual_type = 'graph_raw'\n",
    "# residual_type = 'raw'\n",
    "# residual_type = 'none'## good performances\n",
    "\n",
    "#Bert Config\n",
    "max_wl_role_index = 100\n",
    "max_hop_dis_index = 100\n",
    "max_attr_dis_index = embedding_dimension+1\n",
    "max_inti_pos_index = 100\n",
    "residual_type = residual_type\n",
    "x_size = x_size\n",
    "y_size = y_size\n",
    "k = nclass#Embedding dimension\n",
    "\n",
    "\n",
    "# Network setting\n",
    "hidden_size = 32 #32\n",
    "num_hidden_layers = 1 #2\n",
    "num_attention_heads = 4 #2\n",
    "hidden_act = 'gelu'\n",
    "intermediate_size = 128 #32: 2*hidden_size\n",
    "hidden_dropout_prob = 0.2#0.5\n",
    "attention_probs_dropout_prob = 0.2#0.3\n",
    "initializer_range = 0.02\n",
    "layer_norm_eps = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f800ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass  # simple container\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Input embedding\n",
    "config.x_size = x_size\n",
    "config.hidden_size = hidden_size\n",
    "config.max_wl_role_index = max_wl_role_index\n",
    "config.max_inti_pos_index = max_inti_pos_index\n",
    "config.max_hop_dis_index = max_hop_dis_index\n",
    "# config.max_attr_dis_index = max_attr_dis_index\n",
    "config.layer_norm_eps = layer_norm_eps\n",
    "config.hidden_dropout_prob = hidden_dropout_prob\n",
    "\n",
    "# Encoder\n",
    "config.output_attentions = False\n",
    "config.output_hidden_states = False\n",
    "config.num_hidden_layers = num_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82d42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBertConfig(PretrainedConfig):\n",
    "    # default values\n",
    "    def __init__(\n",
    "        self,\n",
    "        residual_type = 'none',\n",
    "        x_size=3000,\n",
    "        y_size=7,\n",
    "        k=5,\n",
    "        max_wl_role_index = 100,\n",
    "        max_hop_dis_index = 100,\n",
    "        max_inti_pos_index = 100,\n",
    "        # max_attr_dis_index = 100,\n",
    "        hidden_size=32,#32,\n",
    "        num_hidden_layers=1,\n",
    "        num_attention_heads=1,\n",
    "        intermediate_size=32,#32,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.5,#0.5,\n",
    "        attention_probs_dropout_prob=0.5,#0.3,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        is_decoder=False,\n",
    "        input_similarity = None,\n",
    "        input_feature = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(GraphBertConfig, self).__init__(**kwargs)\n",
    "        self.max_wl_role_index = max_wl_role_index\n",
    "        self.max_hop_dis_index = max_hop_dis_index\n",
    "        self.max_inti_pos_index = max_inti_pos_index\n",
    "        # self.max_attr_dis_index = max_attr_dis_index\n",
    "        self.residual_type = residual_type\n",
    "        self.x_size = x_size\n",
    "        self.y_size = y_size\n",
    "        self.k = k\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.hidden_act = hidden_act\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.initializer_range = initializer_range\n",
    "        self.layer_norm_eps = layer_norm_eps\n",
    "        self.is_decoder = is_decoder\n",
    "        self.input_similarity = input_similarity\n",
    "        self.input_feature = input_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11f988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = GraphBertConfig(residual_type = residual_type, k=k, x_size=nfeature, y_size=y_size, \\\n",
    "                            hidden_size=hidden_size, intermediate_size=intermediate_size, \\\n",
    "                            num_attention_heads=num_attention_heads, \\\n",
    "                            num_hidden_layers=num_hidden_layers, \\\n",
    "                            input_similarity = data.adj, \\\n",
    "                            input_feature = data.x \n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4005504",
   "metadata": {},
   "source": [
    "# Pre-training: Node reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d41cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodGraphBertNodeConstruct(BertPreTrainedModel):\n",
    "    learning_record_dict = {}\n",
    "    lr = 0.0001\n",
    "    weight_decay = 5e-4\n",
    "    max_epoch = 200\n",
    "    load_pretrained_path = ''\n",
    "    save_pretrained_path = ''\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(MethodGraphBertNodeConstruct, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.bert = MethodGraphBert(config)\n",
    "        self.cls_y = torch.nn.Linear(config.hidden_size, config.x_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, raw_features, wl_role_ids, init_pos_ids, hop_dis_ids, idx=None):\n",
    "\n",
    "        outputs = self.bert(raw_features, wl_role_ids, init_pos_ids, hop_dis_ids)\n",
    "\n",
    "        sequence_output = 0\n",
    "        for i in range(self.config.k+1):\n",
    "            sequence_output += outputs[0][:,i,:]\n",
    "        sequence_output /= float(self.config.k+1)\n",
    "\n",
    "        x_hat = self.cls_y(sequence_output)\n",
    "\n",
    "        return x_hat\n",
    "    \n",
    "GraphBertNodeConstruct = MethodGraphBertNodeConstruct(bert_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64782593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.0151 time: 0.1794s\n",
      "Epoch: 0011 loss_train: 0.0129 time: 0.1359s\n",
      "Epoch: 0021 loss_train: 0.0122 time: 0.1369s\n",
      "Epoch: 0031 loss_train: 0.0119 time: 0.1313s\n",
      "Epoch: 0041 loss_train: 0.0117 time: 0.1327s\n",
      "Epoch: 0051 loss_train: 0.0116 time: 0.1384s\n",
      "Epoch: 0061 loss_train: 0.0114 time: 0.1332s\n",
      "Epoch: 0071 loss_train: 0.0114 time: 0.1469s\n",
      "Epoch: 0081 loss_train: 0.0113 time: 0.1897s\n",
      "Epoch: 0091 loss_train: 0.0112 time: 0.1323s\n",
      "Epoch: 0101 loss_train: 0.0112 time: 0.1390s\n",
      "Epoch: 0111 loss_train: 0.0111 time: 0.1352s\n",
      "Epoch: 0121 loss_train: 0.0111 time: 0.1736s\n",
      "Epoch: 0131 loss_train: 0.0111 time: 0.1603s\n",
      "Epoch: 0141 loss_train: 0.0111 time: 0.1359s\n",
      "Epoch: 0151 loss_train: 0.0110 time: 0.1557s\n",
      "Epoch: 0161 loss_train: 0.0110 time: 0.1529s\n",
      "Epoch: 0171 loss_train: 0.0110 time: 0.1511s\n",
      "Epoch: 0181 loss_train: 0.0110 time: 0.1587s\n",
      "Epoch: 0191 loss_train: 0.0110 time: 0.1705s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 28.7525s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.75248908996582"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005\n",
    "max_epoch = 200\n",
    "\n",
    "node_learning_record_dict = {}\n",
    "\n",
    "t_begin = time.time()\n",
    "optimizer = optim.AdamW(GraphBertNodeConstruct.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "for epoch in range(max_epoch):\n",
    "    t_epoch_begin = time.time()\n",
    "\n",
    "    # -------------------------\n",
    "\n",
    "    GraphBertNodeConstruct.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = GraphBertNodeConstruct.forward(raw_embeddings, wl_embedding, int_embeddings, hop_embeddings)\n",
    "\n",
    "    # loss_train = F.mse_loss(output, data.x)\n",
    "    loss_train = F.mse_loss(output, data.x)\n",
    "\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    node_learning_record_dict[epoch] = {'loss_train': loss_train.item(), 'time': time.time() - t_epoch_begin}\n",
    "\n",
    "    # -------------------------\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                'time: {:.4f}s'.format(time.time() - t_epoch_begin))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_begin))\n",
    "time.time() - t_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb0c8a",
   "metadata": {},
   "source": [
    "# Fine-Tuning for the real world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcba3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import abc\n",
    "\n",
    "\n",
    "class evaluate:\n",
    "    \"\"\" \n",
    "    evaluate: Abstract Class\n",
    "    Entries: \n",
    "    \"\"\"\n",
    "    \n",
    "    evaluate_name = None\n",
    "    evaluate_description = None\n",
    "    \n",
    "    data = None\n",
    "    \n",
    "    # initialization function\n",
    "    def __init__(self, eName=None, eDescription=None):\n",
    "        self.evaluate_name = eName\n",
    "        self.evaluate_description = eDescription\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def evaluate(self):\n",
    "        return\n",
    "\n",
    "class EvaluateAcc(evaluate):\n",
    "    data = None\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \n",
    "        return accuracy_score(self.data['true_y'], self.data['pred_y'])\n",
    "\n",
    "BertLayerNorm = torch.nn.LayerNorm\n",
    "\n",
    "class MethodGraphBertNodeClassification(BertPreTrainedModel):\n",
    "    learning_record_dict = {}\n",
    "    lr = 0.001\n",
    "    weight_decay = 5e-4\n",
    "    max_epoch = 500\n",
    "    spy_tag = True\n",
    "\n",
    "    load_pretrained_path = ''\n",
    "    save_pretrained_path = ''\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(MethodGraphBertNodeClassification, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.bert = MethodGraphBert(config)\n",
    "        self.res_h = torch.nn.Linear(config.x_size, config.hidden_size)\n",
    "        self.res_y = torch.nn.Linear(config.x_size, config.y_size)\n",
    "        self.cls_y = torch.nn.Linear(config.hidden_size, config.y_size)\n",
    "\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, raw_features, wl_role_ids, init_pos_ids, hop_dis_ids, data, idx=None):\n",
    "        \n",
    "        #Residual\n",
    "        residual_h, residual_y = self.residual_term()\n",
    "        \n",
    "        if idx is not None:\n",
    "            if residual_h is None:\n",
    "                outputs = self.bert(raw_features[idx], wl_role_ids[idx], init_pos_ids[idx], hop_dis_ids[idx], residual_h=None)\n",
    "            else:\n",
    "                outputs = self.bert(raw_features[idx], wl_role_ids[idx], init_pos_ids[idx], hop_dis_ids[idx], residual_h=residual_h[idx])\n",
    "                residual_y = residual_y[idx]\n",
    "            \n",
    "        else:\n",
    "            if residual_h is None:\n",
    "                outputs = self.bert(raw_features, wl_role_ids, init_pos_ids, hop_dis_ids, residual_h=None)\n",
    "            else:\n",
    "                outputs = self.bert(raw_features, wl_role_ids, init_pos_ids, hop_dis_ids, residual_h=residual_h)\n",
    "        \n",
    "        # Average the sequence output\n",
    "        sequence_output = 0\n",
    "        for i in range(self.config.k+1):\n",
    "            sequence_output += outputs[0][:,i,:]\n",
    "        sequence_output /= float(self.config.k+1)#opt1\n",
    "        # sequence_output = outputs[0].mean(dim=1)#opt2\n",
    "        \n",
    "        \n",
    "        labels = self.cls_y(sequence_output)\n",
    "\n",
    "        if residual_y is not None:\n",
    "            labels += residual_y\n",
    "\n",
    "        return F.log_softmax(labels, dim=1)\n",
    "        \n",
    "\n",
    "    def residual_term(self):\n",
    "        if self.config.residual_type == 'none':\n",
    "            return None, None\n",
    "        elif self.config.residual_type == 'raw':\n",
    "            return self.res_h(self.config.input_feature), self.res_y(self.config.input_feature)\n",
    "        elif self.config.residual_type == 'graph_raw':\n",
    "            return torch.spmm(self.config.input_similarity, self.res_h(self.config.input_feature)), torch.spmm(self.config.input_similarity, self.res_y(self.config.input_feature))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1b4e77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodGraphBertNodeClassification(\n",
      "  (bert): MethodGraphBert(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (raw_feature_embeddings): Linear(in_features=1433, out_features=32, bias=True)\n",
      "      (wl_role_embeddings): Embedding(100, 32)\n",
      "      (inti_pos_embeddings): Embedding(100, 32)\n",
      "      (hop_dis_embeddings): Embedding(100, 32)\n",
      "      (LayerNorm): LayerNorm((32,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=32, out_features=32, bias=True)\n",
      "              (key): Linear(in_features=32, out_features=32, bias=True)\n",
      "              (value): Linear(in_features=32, out_features=32, bias=True)\n",
      "              (dropout): Dropout(p=0.5, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=32, out_features=32, bias=True)\n",
      "              (LayerNorm): LayerNorm((32,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.5, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=32, out_features=128, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=128, out_features=32, bias=True)\n",
      "            (LayerNorm): LayerNorm((32,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (res_h): Linear(in_features=1433, out_features=32, bias=True)\n",
      "  (res_y): Linear(in_features=1433, out_features=7, bias=True)\n",
      "  (cls_y): Linear(in_features=32, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "GraphBertNodeClassification = MethodGraphBertNodeClassification(bert_config)\n",
    "print(GraphBertNodeClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a131bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# ------------------------------------\n",
    "# evaluation function\n",
    "def evaluate_in_batches(model, idx_eval, batch_size=10):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        \n",
    "        for idx in idx_eval:\n",
    "            \n",
    "            \n",
    "            label_ouputs = model.forward(raw_embeddings, wl_embedding,\n",
    "                                int_embeddings, hop_embeddings, data, idx)\n",
    "            \n",
    "                \n",
    "            loss_train_cls_residual = F.cross_entropy(label_ouputs, data.y[idx])\n",
    "        \n",
    "            epoch_loss += loss_train_cls_residual.item() * len(data.y[idx])# based on the number of samples\n",
    "            \n",
    "            \n",
    "            #### examine the metrics\n",
    "            probs = F.softmax(label_ouputs, dim=1)  # shape: (batch, 2)\n",
    "            preds = torch.argmax(label_ouputs, dim=1)  # predicted class\n",
    "            \n",
    "            \n",
    "            all_probs.append(probs.numpy())\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(data.y[idx].numpy())\n",
    "            \n",
    "            \n",
    "            epoch_correct += preds.eq(data.y[idx]).sum().item()\n",
    "            epoch_total += len(label_ouputs)\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        loss_train_avg = epoch_loss / epoch_total\n",
    "        acc_train_avg = epoch_correct / epoch_total\n",
    "        \n",
    "        # Calculate AUC\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_preds = np.array(all_preds)\n",
    "        # all_probs = np.array(all_probs)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro')\n",
    "        recall = recall_score(all_labels, all_preds, average='macro')\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        \n",
    "        roc_auc = roc_auc_score(\n",
    "            all_labels, all_probs, multi_class='ovr')\n",
    "        \n",
    "        \n",
    "        cm = confusion_matrix(all_labels, all_preds).ravel()\n",
    "            \n",
    "    return acc_train_avg, loss_train_avg, accuracy, precision, recall, f1, roc_auc, cm\n",
    "\n",
    "# ------------------------------------\n",
    "# early stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.0, mode='min', path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.mode = mode\n",
    "        self.path = path\n",
    "\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = None\n",
    "\n",
    "        if self.mode not in ['min', 'max']:\n",
    "            raise ValueError(\"mode must be 'min' or 'max'\")\n",
    "\n",
    "    def __call__(self, val_metric, model, epoch=None):\n",
    "        score = val_metric if self.mode == 'min' else -val_metric\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            self.save_checkpoint(model, val_metric)\n",
    "        elif score < self.best_score - self.delta:  # ✅ only when truly improved\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model, val_metric)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"No improvement. EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, model, val_metric):\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        print(f\"Model improved. Saved to {self.path} | Val Metric: {val_metric:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f126eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001\n",
      "  [Train] loss: 1.8452 | acc: 0.3214\n",
      "  [Valid] loss: 1.6506 | acc: 0.3567\n",
      "  [Test ] loss: 1.5632 | acc: 0.4360\n",
      "  Time: 0.1658s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 1.6506\n",
      "Epoch: 0002\n",
      "  [Train] loss: 1.2109 | acc: 0.6643\n",
      "  [Valid] loss: 1.3621 | acc: 0.4867\n",
      "  [Test ] loss: 1.2272 | acc: 0.5660\n",
      "  Time: 0.1417s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 1.3621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Python_interpre/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003\n",
      "  [Train] loss: 0.7017 | acc: 0.8929\n",
      "  [Valid] loss: 1.0740 | acc: 0.6933\n",
      "  [Test ] loss: 0.9216 | acc: 0.7410\n",
      "  Time: 0.1562s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 1.0740\n",
      "Epoch: 0004\n",
      "  [Train] loss: 0.3380 | acc: 0.9857\n",
      "  [Valid] loss: 0.9706 | acc: 0.6933\n",
      "  [Test ] loss: 0.8095 | acc: 0.7570\n",
      "  Time: 0.1344s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 0.9706\n",
      "Epoch: 0005\n",
      "  [Train] loss: 0.1572 | acc: 0.9929\n",
      "  [Valid] loss: 0.8119 | acc: 0.7600\n",
      "  [Test ] loss: 0.7011 | acc: 0.7900\n",
      "  Time: 0.1384s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 0.8119\n",
      "Epoch: 0006\n",
      "  [Train] loss: 0.0698 | acc: 0.9929\n",
      "  [Valid] loss: 0.7325 | acc: 0.7767\n",
      "  [Test ] loss: 0.6633 | acc: 0.8070\n",
      "  Time: 0.1351s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 0.7325\n",
      "Epoch: 0007\n",
      "  [Train] loss: 0.0310 | acc: 1.0000\n",
      "  [Valid] loss: 0.7285 | acc: 0.7767\n",
      "  [Test ] loss: 0.6782 | acc: 0.8100\n",
      "  Time: 0.1301s\n",
      "-----------------------------------------\n",
      "Model improved. Saved to ./results/checkpoint.pt | Val Metric: 0.7285\n",
      "Epoch: 0008\n",
      "  [Train] loss: 0.0152 | acc: 1.0000\n",
      "  [Valid] loss: 0.7673 | acc: 0.7600\n",
      "  [Test ] loss: 0.7187 | acc: 0.8060\n",
      "  Time: 0.1271s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 1/30\n",
      "Epoch: 0009\n",
      "  [Train] loss: 0.0092 | acc: 1.0000\n",
      "  [Valid] loss: 0.8104 | acc: 0.7600\n",
      "  [Test ] loss: 0.7628 | acc: 0.8020\n",
      "  Time: 0.1320s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 2/30\n",
      "Epoch: 0010\n",
      "  [Train] loss: 0.0092 | acc: 1.0000\n",
      "  [Valid] loss: 0.8320 | acc: 0.7567\n",
      "  [Test ] loss: 0.7883 | acc: 0.8020\n",
      "  Time: 0.1249s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 3/30\n",
      "Epoch: 0011\n",
      "  [Train] loss: 0.0060 | acc: 1.0000\n",
      "  [Valid] loss: 0.8325 | acc: 0.7567\n",
      "  [Test ] loss: 0.7916 | acc: 0.8040\n",
      "  Time: 0.1312s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 4/30\n",
      "Epoch: 0012\n",
      "  [Train] loss: 0.0052 | acc: 1.0000\n",
      "  [Valid] loss: 0.8230 | acc: 0.7667\n",
      "  [Test ] loss: 0.7874 | acc: 0.8040\n",
      "  Time: 0.1242s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 5/30\n",
      "Epoch: 0013\n",
      "  [Train] loss: 0.0028 | acc: 1.0000\n",
      "  [Valid] loss: 0.8089 | acc: 0.7667\n",
      "  [Test ] loss: 0.7802 | acc: 0.8060\n",
      "  Time: 0.1296s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 6/30\n",
      "Epoch: 0014\n",
      "  [Train] loss: 0.0023 | acc: 1.0000\n",
      "  [Valid] loss: 0.8046 | acc: 0.7667\n",
      "  [Test ] loss: 0.7779 | acc: 0.8010\n",
      "  Time: 0.1243s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 7/30\n",
      "Epoch: 0015\n",
      "  [Train] loss: 0.0018 | acc: 1.0000\n",
      "  [Valid] loss: 0.8010 | acc: 0.7633\n",
      "  [Test ] loss: 0.7754 | acc: 0.8020\n",
      "  Time: 0.1287s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 8/30\n",
      "Epoch: 0016\n",
      "  [Train] loss: 0.0020 | acc: 1.0000\n",
      "  [Valid] loss: 0.7979 | acc: 0.7700\n",
      "  [Test ] loss: 0.7730 | acc: 0.8030\n",
      "  Time: 0.1242s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 9/30\n",
      "Epoch: 0017\n",
      "  [Train] loss: 0.0017 | acc: 1.0000\n",
      "  [Valid] loss: 0.7966 | acc: 0.7700\n",
      "  [Test ] loss: 0.7717 | acc: 0.8040\n",
      "  Time: 0.1343s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 10/30\n",
      "Epoch: 0018\n",
      "  [Train] loss: 0.0017 | acc: 1.0000\n",
      "  [Valid] loss: 0.7952 | acc: 0.7700\n",
      "  [Test ] loss: 0.7701 | acc: 0.8040\n",
      "  Time: 0.1313s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 11/30\n",
      "Epoch: 0019\n",
      "  [Train] loss: 0.0016 | acc: 1.0000\n",
      "  [Valid] loss: 0.7940 | acc: 0.7700\n",
      "  [Test ] loss: 0.7687 | acc: 0.8040\n",
      "  Time: 0.1318s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 12/30\n",
      "Epoch: 0020\n",
      "  [Train] loss: 0.0019 | acc: 1.0000\n",
      "  [Valid] loss: 0.7935 | acc: 0.7700\n",
      "  [Test ] loss: 0.7681 | acc: 0.8050\n",
      "  Time: 0.1257s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 13/30\n",
      "Epoch: 0021\n",
      "  [Train] loss: 0.0020 | acc: 1.0000\n",
      "  [Valid] loss: 0.7930 | acc: 0.7700\n",
      "  [Test ] loss: 0.7675 | acc: 0.8050\n",
      "  Time: 0.1296s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 14/30\n",
      "Epoch: 0022\n",
      "  [Train] loss: 0.0017 | acc: 1.0000\n",
      "  [Valid] loss: 0.7924 | acc: 0.7700\n",
      "  [Test ] loss: 0.7670 | acc: 0.8050\n",
      "  Time: 0.1251s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 15/30\n",
      "Epoch: 0023\n",
      "  [Train] loss: 0.0022 | acc: 1.0000\n",
      "  [Valid] loss: 0.7921 | acc: 0.7700\n",
      "  [Test ] loss: 0.7667 | acc: 0.8050\n",
      "  Time: 0.1299s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 16/30\n",
      "Epoch: 0024\n",
      "  [Train] loss: 0.0020 | acc: 1.0000\n",
      "  [Valid] loss: 0.7917 | acc: 0.7700\n",
      "  [Test ] loss: 0.7663 | acc: 0.8050\n",
      "  Time: 0.1245s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 17/30\n",
      "Epoch: 0025\n",
      "  [Train] loss: 0.0018 | acc: 1.0000\n",
      "  [Valid] loss: 0.7914 | acc: 0.7700\n",
      "  [Test ] loss: 0.7660 | acc: 0.8050\n",
      "  Time: 0.1283s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 18/30\n",
      "Epoch: 0026\n",
      "  [Train] loss: 0.0019 | acc: 1.0000\n",
      "  [Valid] loss: 0.7912 | acc: 0.7700\n",
      "  [Test ] loss: 0.7658 | acc: 0.8050\n",
      "  Time: 0.1302s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 19/30\n",
      "Epoch: 0027\n",
      "  [Train] loss: 0.0016 | acc: 1.0000\n",
      "  [Valid] loss: 0.7911 | acc: 0.7700\n",
      "  [Test ] loss: 0.7656 | acc: 0.8050\n",
      "  Time: 0.1323s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 20/30\n",
      "Epoch: 0028\n",
      "  [Train] loss: 0.0020 | acc: 1.0000\n",
      "  [Valid] loss: 0.7909 | acc: 0.7733\n",
      "  [Test ] loss: 0.7655 | acc: 0.8050\n",
      "  Time: 0.1278s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 21/30\n",
      "Epoch: 0029\n",
      "  [Train] loss: 0.0016 | acc: 1.0000\n",
      "  [Valid] loss: 0.7909 | acc: 0.7733\n",
      "  [Test ] loss: 0.7654 | acc: 0.8050\n",
      "  Time: 0.1367s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 22/30\n",
      "Epoch: 0030\n",
      "  [Train] loss: 0.0015 | acc: 1.0000\n",
      "  [Valid] loss: 0.7908 | acc: 0.7733\n",
      "  [Test ] loss: 0.7653 | acc: 0.8050\n",
      "  Time: 0.1343s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 23/30\n",
      "Epoch: 0031\n",
      "  [Train] loss: 0.0014 | acc: 1.0000\n",
      "  [Valid] loss: 0.7908 | acc: 0.7733\n",
      "  [Test ] loss: 0.7652 | acc: 0.8050\n",
      "  Time: 0.1333s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 24/30\n",
      "Epoch: 0032\n",
      "  [Train] loss: 0.0016 | acc: 1.0000\n",
      "  [Valid] loss: 0.7907 | acc: 0.7733\n",
      "  [Test ] loss: 0.7652 | acc: 0.8050\n",
      "  Time: 0.1326s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 25/30\n",
      "Epoch: 0033\n",
      "  [Train] loss: 0.0014 | acc: 1.0000\n",
      "  [Valid] loss: 0.7907 | acc: 0.7733\n",
      "  [Test ] loss: 0.7651 | acc: 0.8050\n",
      "  Time: 0.1369s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 26/30\n",
      "Epoch: 0034\n",
      "  [Train] loss: 0.0018 | acc: 1.0000\n",
      "  [Valid] loss: 0.7907 | acc: 0.7733\n",
      "  [Test ] loss: 0.7651 | acc: 0.8050\n",
      "  Time: 0.1319s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 27/30\n",
      "Epoch: 0035\n",
      "  [Train] loss: 0.0018 | acc: 1.0000\n",
      "  [Valid] loss: 0.7907 | acc: 0.7733\n",
      "  [Test ] loss: 0.7651 | acc: 0.8050\n",
      "  Time: 0.1349s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 28/30\n",
      "Epoch: 0036\n",
      "  [Train] loss: 0.0017 | acc: 1.0000\n",
      "  [Valid] loss: 0.7906 | acc: 0.7733\n",
      "  [Test ] loss: 0.7650 | acc: 0.8050\n",
      "  Time: 0.1326s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 29/30\n",
      "Epoch: 0037\n",
      "  [Train] loss: 0.0017 | acc: 1.0000\n",
      "  [Valid] loss: 0.7906 | acc: 0.7733\n",
      "  [Test ] loss: 0.7650 | acc: 0.8050\n",
      "  Time: 0.1349s\n",
      "-----------------------------------------\n",
      "No improvement. EarlyStopping counter: 30/30\n",
      "Early stopping triggered.\n",
      "Optimization Finished!\n",
      "Total time elapsed: 4.9206s,     best testing performance  0.810000, minimun loss  0.663282\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Separate dataset for purpose, we only use limited dataset 140 nodes for training to test relatively big dataset\n",
    "idx_train = range(140)\n",
    "idx_test = range(200, 1200)\n",
    "idx_val = range(1200, 1500)\n",
    "\n",
    "\n",
    "classify_learning_record_dict = {}\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_loader = DataLoader(idx_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(idx_test, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(idx_val, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "params = []\n",
    "base_lr = 1e-3\n",
    "decay_factor = 0.9\n",
    "for i, (name, param) in enumerate(GraphBertNodeClassification.named_parameters()):\n",
    "    lr = base_lr * (decay_factor ** (len(list(GraphBertNodeClassification.named_children())) - i - 1))\n",
    "    params.append({'params': param, 'lr': lr})\n",
    "    \n",
    "# ------------------------------------\n",
    "max_epoch = 100\n",
    "\n",
    "\n",
    "t_begin = time.time()\n",
    "\n",
    "optimizer = optim.Adam(params, lr=base_lr, weight_decay=1e-4)\n",
    "\n",
    "accuracy = EvaluateAcc('', '')\n",
    "\n",
    "# initialization \n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "\n",
    "classify_learning_record_dict = {}\n",
    "\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(patience=30, mode='min', path=f'./results/checkpoint.pt')\n",
    "\n",
    "\n",
    "max_score = 0.0\n",
    "for epoch in range(max_epoch):\n",
    "    t_epoch_begin = time.time()\n",
    "\n",
    "    GraphBertNodeClassification.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    \n",
    "    for load in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()            \n",
    "        \n",
    "        output  = GraphBertNodeClassification.forward(\n",
    "            raw_embeddings, wl_embedding, int_embeddings, hop_embeddings, data, idx=load)\n",
    "        \n",
    "        # Two loss functions\n",
    "        loss_train = F.cross_entropy(output, data.y[load])\n",
    "        \n",
    "        loss_train.backward()\n",
    "        \n",
    "        pred = (output).max(1)[1]\n",
    "        correct = pred.eq(data.y[load]).sum().item()\n",
    "\n",
    "        # epoch_loss += loss_train.item() * len(batch_idx)\n",
    "        epoch_loss += loss_train.item() * len(load)# based on the number of samples\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        epoch_correct += correct\n",
    "        \n",
    "        # epoch_total += len(batch_idx)\n",
    "        epoch_total += len(load)\n",
    "        \n",
    "        \n",
    "        # print(f\"Batch {i+1}/{num_batches}, Loss: {loss_train.item():.4f}, Accuracy: {correct/len(batch_idx):.4f}\")\n",
    "        \n",
    "\n",
    "    loss_train_avg = epoch_loss / epoch_total\n",
    "    acc_train_avg = epoch_correct / epoch_total\n",
    "\n",
    "    # evaluation\n",
    "    GraphBertNodeClassification.eval()#frozen\n",
    "    \n",
    "    # Validate (using mini-batch)\n",
    "    acc_val, loss_val, accuracy_val, precision_val, recall_val, f1_val, roc_auc_val, confusion_matrix_val = evaluate_in_batches(GraphBertNodeClassification, val_loader, batch_size=20)\n",
    "\n",
    "    # Test (using mini-batch)\n",
    "    acc_test, loss_test, accuracy_test, precision_test, recall_test, f1_test, roc_auc_test, confusion_matrix_test = evaluate_in_batches(GraphBertNodeClassification, test_loader, batch_size=20)\n",
    "\n",
    "    classify_learning_record_dict[epoch] = {\n",
    "        'loss_train': loss_train_avg,\n",
    "        'acc_train': acc_train_avg,\n",
    "        'loss_val': loss_val,\n",
    "        'acc_val': acc_val,\n",
    "        'loss_test': loss_test,\n",
    "        'acc_test': acc_test,\n",
    "        'time': time.time() - t_epoch_begin\n",
    "    }\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:04d}\")\n",
    "    print(f\"  [Train] loss: {loss_train_avg:.4f} | acc: {acc_train_avg:.4f}\")\n",
    "    print(f\"  [Valid] loss: {loss_val:.4f} | acc: {acc_val:.4f}\")\n",
    "    print(f\"  [Test ] loss: {loss_test:.4f} | acc: {acc_test:.4f}\")\n",
    "    print(f\"  Time: {time.time() - t_epoch_begin:.4f}s\")\n",
    "    print('-----------------------------------------')\n",
    "    \n",
    "    #lr scheduler\n",
    "    scheduler.step(loss_val)\n",
    "    \n",
    "\n",
    "    early_stopping(loss_val, GraphBertNodeClassification)\n",
    "    \n",
    "    # Early stopping\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_begin) + ', \\\n",
    "    best testing performance {: 4f}'.format(np.max([classify_learning_record_dict[epoch]['acc_test'] for epoch in classify_learning_record_dict])) \\\n",
    "        + ', minimun loss {: 4f}'.format(np.min([classify_learning_record_dict[epoch]['loss_test'] for epoch in classify_learning_record_dict])))\n",
    "\n",
    "\n",
    "\n",
    "torch.save(classify_learning_record_dict, f'./results/classify_learning_record_dict.pth')\n",
    "    \n",
    "torch.save(GraphBertNodeClassification.state_dict(), './results/model_dict.pt')\n",
    "print(f\"Model saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a29566",
   "metadata": {},
   "source": [
    "# making the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "248f2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/jlhdr74n64dfb6pm21lq8x180000gn/T/ipykernel_47623/2323198184.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classify_learning_record_dict = torch.load(f'/Users/bobtian/github/GraphBert/results/classify_learning_record_dict.pth')\n"
     ]
    }
   ],
   "source": [
    "classify_learning_record_dict = torch.load(f'/Users/bobtian/github/GraphBert/results/classify_learning_record_dict.pth')\n",
    "\n",
    "# Get the keys of the dictionary\n",
    "for key in range(len(classify_learning_record_dict)):\n",
    "    df = pd.DataFrame.from_dict(classify_learning_record_dict[key], orient='index')\n",
    "    df = df.sort_index()\n",
    "    \n",
    "#     ## average the values across all indices\n",
    "#     all_series.append(df.mean(axis=0))\n",
    "    \n",
    "# all_series = pd.DataFrame(all_series)\n",
    "# all_series.rename(columns={'accuracy_test': f'accuracy_test_{i}'}, inplace=True)\n",
    "# all_series.rename(columns={'loss_test': f'loss_test_{i}'}, inplace=True)\n",
    "# all_series.rename(columns={'time': f'time_{i}'}, inplace=True)\n",
    "\n",
    "# result_df_acc_test.append( all_series[f'accuracy_test_{i}'] )\n",
    "# result_df_loss_test.append( all_series[f'loss_test_{i}'] )\n",
    "# result_df_time_test.append( all_series[f'time_{i}'] )\n",
    "\n",
    "# result_df_acc_test = pd.DataFrame(result_df_acc_test) \n",
    "# result_df_loss_test = pd.DataFrame(result_df_loss_test) \n",
    "# result_df_time_test = pd.DataFrame(result_df_time_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "517d64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_training=[]\n",
    "loss_val=[]\n",
    "\n",
    "acc_train = []\n",
    "acc_val = []\n",
    "acc_test = []\n",
    "\n",
    "for key in classify_learning_record_dict:\n",
    "    df = pd.DataFrame.from_dict(classify_learning_record_dict[key], orient='index')\n",
    "    loss_training.append(df.loc['loss_train'].values[0])\n",
    "    loss_val.append(df.loc['loss_val'].values[0])\n",
    "    \n",
    "    acc_train.append(df.loc['acc_train'].values[0])\n",
    "    acc_test.append(df.loc['acc_test'].values[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e563d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(loss_training) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, loss_training, 'o-', label='Train Loss')\n",
    "plt.plot(epochs, loss_val, 'o-', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Curve')\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, acc_train, 'o-', label='Train Accuracy')\n",
    "plt.plot(epochs, acc_test, 'o-', label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Curve')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_interpre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
